{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qX-DXe1tNR9E",
        "outputId": "89061eb0-b6ca-4466-e15a-e8737c539f38"
      },
      "outputs": [],
      "source": [
        "pip install tokenizers datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwdgvAH0NTDh",
        "outputId": "7f268643-0e77-4d64-a9d4-085aa35b04e0"
      },
      "outputs": [],
      "source": [
        "pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Dh2FAHeNtwv"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Log in to Hugging Face\n",
        "login(token=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "a58682dd26a9455e97339011524841a7",
            "9f8c1ccb7af54a048d32b84908ef75b6",
            "ce44d90249c24c1599e16fab4e7b8ea2",
            "f6b9a83d310a4d008786d8502872736f",
            "e3595975c9e64becbf2958dc32871212",
            "35cf516beb3f4e15b7d908ddd9f148a8",
            "c618d8b7a73647aab016fc96c81c1959",
            "2e0f47d5f132402faa9f9733a889055b",
            "6a1608dd1fb948af96ea4de4ba06d2e9",
            "364bc5c2cbf64d439bcf02cab4f3502f",
            "fa6015372b6546cb9b0de03fecc9a963"
          ]
        },
        "id": "KV2HjWGdN1eK",
        "outputId": "35207f5e-ddb9-4bdd-ef78-91ed15c77c3b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a58682dd26a9455e97339011524841a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/917 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IterableDataset({\n",
            "    features: ['blob_id', 'directory_id', 'path', 'content_id', 'detected_licenses', 'license_type', 'repo_name', 'snapshot_id', 'revision_id', 'branch_name', 'visit_date', 'revision_date', 'committer_date', 'github_id', 'star_events_count', 'fork_events_count', 'gha_license_id', 'gha_event_created_at', 'gha_created_at', 'gha_language', 'src_encoding', 'language', 'is_vendor', 'is_generated', 'length_bytes', 'extension'],\n",
            "    num_shards: 9\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Hugging Face 'The Stack - V2' which contains 67.5 TB of source code files. Python is among the major languages represented containing 80.6 M rows.\n",
        "# Efficiently loading only the 'Python' subset and 'streaming=True' to process data batch by batch.\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"bigcode/the-stack-v2\", \"Python\", split=\"train\", streaming=True)\n",
        "\n",
        "# Inspect the dataset\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DToVIvOmN7X1",
        "outputId": "b46f0ceb-cc01-4cd7-e634-67c49e5ba381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'blob_id': 'd44bbb217114c0831167824d694d57c29ab86665', 'directory_id': 'e3f3f911019ac126d01c056eafc7c3183107a5af', 'path': '/Traffic Sign Detection/all_signs_combined/src/predict.py', 'content_id': '19ed9a428015b625610be9930dfee35938fb451b', 'detected_licenses': [], 'license_type': 'no_license', 'repo_name': 'uncctrafficsigndetection/Traffic-Sign-Detection', 'snapshot_id': '595258766f865c4b3c628b002d7b93a774168a9b', 'revision_id': '3ff4be52357f4b6340fef94124f8c835ab66fd8a', 'branch_name': 'refs/heads/master', 'visit_date': datetime.datetime(2020, 4, 9, 20, 28, 33, 910961), 'revision_date': datetime.datetime(2018, 12, 5, 21, 29, 50), 'committer_date': datetime.datetime(2018, 12, 5, 21, 29, 50), 'github_id': 160574509, 'star_events_count': 0, 'fork_events_count': 0, 'gha_license_id': None, 'gha_event_created_at': None, 'gha_created_at': None, 'gha_language': None, 'src_encoding': 'UTF-8', 'language': 'Python', 'is_vendor': False, 'is_generated': False, 'length_bytes': 959, 'extension': 'py'}\n",
            "{'blob_id': 'f82a7850addf3773f1ce92a89e4d51f96cf3f763', 'directory_id': '487ce91881032c1de16e35ed8bc187d6034205f7', 'path': '/codes/CodeJamCrawler/16_0_2_neat/16_0_2_tkdkop_pancake.py', 'content_id': '259ec04a68548d92ceed7f438162fc6b46baa760', 'detected_licenses': [], 'license_type': 'no_license', 'repo_name': 'DaHuO/Supergraph', 'snapshot_id': '9cd26d8c5a081803015d93cf5f2674009e92ef7e', 'revision_id': 'c88059dc66297af577ad2b8afa4e0ac0ad622915', 'branch_name': 'refs/heads/master', 'visit_date': datetime.datetime(2021, 6, 14, 16, 7, 52, 405091), 'revision_date': datetime.datetime(2016, 8, 21, 13, 39, 13), 'committer_date': datetime.datetime(2016, 8, 21, 13, 39, 13), 'github_id': 49829508, 'star_events_count': 2, 'fork_events_count': 0, 'gha_license_id': None, 'gha_event_created_at': datetime.datetime(2021, 3, 19, 21, 55, 46), 'gha_created_at': datetime.datetime(2016, 1, 17, 18, 23), 'gha_language': 'Python', 'src_encoding': 'UTF-8', 'language': 'Python', 'is_vendor': False, 'is_generated': False, 'length_bytes': 286, 'extension': 'py'}\n",
            "{'blob_id': 'fb2c64c0218df858e821204c4c485f29f4b33c74', 'directory_id': 'e0527bce5c53a196752d3a16adf50cb60754de5f', 'path': '/10-How to Stop Programs Crashing Demos/3-is_square.py', 'content_id': '8bf01fcece7fa35279f95d25ece62fa140398965', 'detected_licenses': [], 'license_type': 'no_license', 'repo_name': 'ARWA-ALraddadi/python-tutorial-for-beginners', 'snapshot_id': 'ddeb657f419fbc176bea273bc9fb6b88d1894191', 'revision_id': '21cedfc47871ca4d25c2382464c60ab0a2121205', 'branch_name': 'refs/heads/master', 'visit_date': datetime.datetime(2023, 6, 30, 20, 24, 30, 688800), 'revision_date': datetime.datetime(2021, 8, 8, 8, 22, 29), 'committer_date': datetime.datetime(2021, 8, 8, 8, 22, 29), 'github_id': 193094651, 'star_events_count': 0, 'fork_events_count': 0, 'gha_license_id': None, 'gha_event_created_at': None, 'gha_created_at': None, 'gha_language': None, 'src_encoding': 'UTF-8', 'language': 'Python', 'is_vendor': False, 'is_generated': False, 'length_bytes': 3066, 'extension': 'py'}\n",
            "{'blob_id': '2cf1cde00eea109a46c3e5983b4906feef72866f', 'directory_id': 'f0856e60a095ce99ec3497b3f27567803056ac60', 'path': '/keras2/keras66_gradient2.py', 'content_id': '0e0d0cc1f27912ef32b11753f760a7606dd315f8', 'detected_licenses': [], 'license_type': 'no_license', 'repo_name': 'hjuju/TF_Study-HAN', 'snapshot_id': 'dcbac17ce8b8885f5fb7d7f554230c2948fda9ac', 'revision_id': 'c0faf98380e7f220868ddf83a9aaacaa4ebd2c2a', 'branch_name': 'refs/heads/main', 'visit_date': datetime.datetime(2023, 9, 4, 9, 13, 33, 212258), 'revision_date': datetime.datetime(2021, 10, 27, 8, 0, 49), 'committer_date': datetime.datetime(2021, 10, 27, 8, 0, 49), 'github_id': 384371952, 'star_events_count': 1, 'fork_events_count': 0, 'gha_license_id': None, 'gha_event_created_at': None, 'gha_created_at': None, 'gha_language': None, 'src_encoding': 'UTF-8', 'language': 'Python', 'is_vendor': False, 'is_generated': False, 'length_bytes': 479, 'extension': 'py'}\n",
            "{'blob_id': '434458353e5d0a52d12ede2591e66addc5e8ffbb', 'directory_id': '79c15f777a3948d6e20e44aa46fa2c33ed11e079', 'path': '/setup.py', 'content_id': '8031de8933cb5ced139e37ffba850030819d0400', 'detected_licenses': ['BSD-3-Clause'], 'license_type': 'permissive', 'repo_name': 'Chinmay-395/channels_redis', 'snapshot_id': '7249b17514acb9147fe99dd70fc77c63a1a2dde7', 'revision_id': 'cd7a171bf7891707b5de385519f909c537eaed8c', 'branch_name': 'refs/heads/master', 'visit_date': datetime.datetime(2022, 9, 5, 21, 10, 20, 914002), 'revision_date': datetime.datetime(2020, 5, 14, 10, 32, 6), 'committer_date': datetime.datetime(2020, 5, 14, 10, 32, 6), 'github_id': None, 'star_events_count': 0, 'fork_events_count': 0, 'gha_license_id': None, 'gha_event_created_at': None, 'gha_created_at': None, 'gha_language': None, 'src_encoding': 'UTF-8', 'language': 'Python', 'is_vendor': False, 'is_generated': False, 'length_bytes': 1062, 'extension': 'py'}\n"
          ]
        }
      ],
      "source": [
        "for sample in dataset.take(5):\n",
        "    print(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-zMpKB5OrBX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set AWS credentials (Enter your own keys)\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"\"\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrmzXVfNOv2n",
        "outputId": "5ac2e68b-484e-4fa9-80af-5220bc94d2bf"
      },
      "outputs": [],
      "source": [
        "pip install smart_open[s3] boto3 datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503,
          "referenced_widgets": [
            "ecd3caac3823445bae4b7dfb1e25bb0f",
            "8e0a431fb92343f7b0ecb10923998437",
            "08a49e224f3043358f77fc0c6c5bbd29",
            "439f09348e1b4d058a4e70e26cdcdc04",
            "7e05646c1b204ee68c8d9af022ac7931",
            "b2a7ae97e6d54672a47b182873d24ca5",
            "bac57e80a4074946ac510eadb81187ff",
            "e53b6b865b8e41fbbf12592321856fa8",
            "cda142d7c5df429a9f3c3e6c5cd8c0b6",
            "9e256c9f504546e3afc2f311c3be9263",
            "d59cf93c137844928e43120b543179bb"
          ]
        },
        "id": "IXPBuW1kOylb",
        "outputId": "bc040b45-608a-48d7-a211-2a72b8598fc5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import boto3\n",
        "from smart_open import open\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Set up AWS session\n",
        "session = boto3.Session(\n",
        "    aws_access_key_id=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
        "    aws_secret_access_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
        ")\n",
        "s3 = session.client(\"s3\")\n",
        "\n",
        "# Function to download file contents\n",
        "def download_contents(row):\n",
        "    blob_id = row[\"blob_id\"]\n",
        "    src_encoding = row[\"src_encoding\"]\n",
        "    s3_url = f\"s3://softwareheritage/content/{blob_id}\"\n",
        "\n",
        "    with open(s3_url, \"rb\", compression=\".gz\", transport_params={\"client\": s3}) as fin:\n",
        "        content = fin.read().decode(src_encoding)\n",
        "\n",
        "    return {\"content\": content}\n",
        "\n",
        "# Load the dataset\n",
        "ds = load_dataset(\"bigcode/the-stack-v2\",\"Python\", split=\"train\", streaming=True)\n",
        "\n",
        "# Map the download function to the dataset\n",
        "ds = ds.map(download_contents)\n",
        "\n",
        "# Inspect the first sample\n",
        "for row in ds:\n",
        "    print(row[\"content\"])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JkQuT2cqO1OO"
      },
      "outputs": [],
      "source": [
        "# Save the first 10000 samples to a file\n",
        "with open(\"python_code.txt\", \"w\") as f:\n",
        "    for i, row in enumerate(ds):\n",
        "        if i >= 10000:  # Adjust the number of samples as needed\n",
        "            break\n",
        "        f.write(row[\"content\"] + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "leBuTz9nO4Lh"
      },
      "outputs": [],
      "source": [
        "# Load the original dataset\n",
        "with open(\"python_code.txt\", \"r\") as f:\n",
        "    code_samples = f.readlines()\n",
        "\n",
        "# Split the dataset into training and held-out sets\n",
        "train_size = int(0.9 * len(code_samples))  # 90% for training\n",
        "train_samples = code_samples[:train_size]\n",
        "held_out_samples = code_samples[train_size:]\n",
        "\n",
        "# Save the training set\n",
        "with open(\"train_python_code.txt\", \"w\") as f:\n",
        "    f.writelines(train_samples)\n",
        "\n",
        "# Save the held-out set\n",
        "with open(\"held_out_python_code.txt\", \"w\") as f:\n",
        "    f.writelines(held_out_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PqFIxumkPPl3"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
        "\n",
        "# Initialize BPE tokenizer\n",
        "bpe_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
        "bpe_tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "\n",
        "# Train the tokenizer\n",
        "trainer = trainers.BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], vocab_size=10000)\n",
        "bpe_tokenizer.train(files=[\"python_code.txt\"], trainer=trainer)\n",
        "\n",
        "# Save the tokenizer\n",
        "bpe_tokenizer.save(\"bpe_tokenizer.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlqKwVmXPQgw",
        "outputId": "b50a7267-5038-4762-9c67-4d5f9ce41438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens: ['def', 'add', '(', 'a', ',', 'b', '):', 'return', 'a', '+', 'b']\n",
            "IDs: [4557, 4834, 16, 73, 20, 74, 4538, 4594, 73, 19, 74]\n"
          ]
        }
      ],
      "source": [
        "from tokenizers import Tokenizer\n",
        "\n",
        "# Load the trained BPE tokenizer\n",
        "bpe_tokenizer = Tokenizer.from_file(\"bpe_tokenizer.json\")\n",
        "\n",
        "# Sample Python code\n",
        "sample_code = \"\"\"\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the sample code\n",
        "output = bpe_tokenizer.encode(sample_code)\n",
        "print(\"Tokens:\", output.tokens)\n",
        "print(\"IDs:\", output.ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qM5YE1ZPTGE",
        "outputId": "2c7a5cf3-8614-4444-b48a-71177a28ea54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenization Time: 42.46228647232056 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Load a large dataset\n",
        "with open(\"python_code.txt\", \"r\") as f:\n",
        "    large_code = f.read()\n",
        "\n",
        "# Measure tokenization time\n",
        "start_time = time.time()\n",
        "output = bpe_tokenizer.encode(large_code)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Tokenization Time:\", end_time - start_time, \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Ay2WPbZDPVIo"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer\n",
        "\n",
        "# Load the trained BPE tokenizer\n",
        "bpe_tokenizer = Tokenizer.from_file(\"bpe_tokenizer.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GE7g1x6PXPv",
        "outputId": "1cd0da7e-de3a-486e-cad3-b2e3d30857e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 10000\n"
          ]
        }
      ],
      "source": [
        "vocab_size = bpe_tokenizer.get_vocab_size()\n",
        "print(\"Vocabulary Size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlFXIJdzPZEa",
        "outputId": "1649aa50-872b-4a01-c6e4-d139977f6595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Tokens per Sentence: 10.974699436946016\n"
          ]
        }
      ],
      "source": [
        "# Load a dataset of Python code\n",
        "with open(\"python_code.txt\", \"r\") as f:\n",
        "    code_samples = f.readlines()\n",
        "\n",
        "# Tokenize each sample and count the number of tokens\n",
        "total_tokens = 0\n",
        "total_samples = len(code_samples)\n",
        "\n",
        "for code in code_samples:\n",
        "    output = bpe_tokenizer.encode(code)\n",
        "    total_tokens += len(output.tokens)\n",
        "\n",
        "# Calculate the average number of tokens per sentence\n",
        "avg_tokens_per_sentence = total_tokens / total_samples\n",
        "print(\"Average Tokens per Sentence:\", avg_tokens_per_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9lBtF8IPa6H",
        "outputId": "622d3954-960c-4dc3-a59a-68decccd0bf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OOV Rate: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Load a held-out dataset\n",
        "with open(\"held_out_python_code.txt\", \"r\") as f:\n",
        "    held_out_code = f.read()\n",
        "\n",
        "# Tokenize the held-out code\n",
        "output = bpe_tokenizer.encode(held_out_code)\n",
        "\n",
        "# Count the number of OOV tokens\n",
        "oov_tokens = [token for token in output.tokens if token == \"[UNK]\"]\n",
        "num_oov_tokens = len(oov_tokens)\n",
        "total_tokens = len(output.tokens)\n",
        "\n",
        "# Calculate the OOV rate\n",
        "oov_rate = num_oov_tokens / total_tokens\n",
        "print(\"OOV Rate:\", oov_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "R_t3QYkiPcnE"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
        "\n",
        "# Initialize WordPiece tokenizer\n",
        "wordpiece_tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n",
        "\n",
        "# Use a pre-tokenizer to split input into words\n",
        "wordpiece_tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "\n",
        "# Define a trainer\n",
        "wordpiece_trainer = trainers.WordPieceTrainer(\n",
        "    special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"],\n",
        "    vocab_size=10000  # Adjust vocabulary size as needed\n",
        ")\n",
        "\n",
        "# Train the tokenizer\n",
        "wordpiece_tokenizer.train(files=[\"train_python_code.txt\"], trainer=wordpiece_trainer)\n",
        "\n",
        "# Save the tokenizer\n",
        "wordpiece_tokenizer.save(\"wordpiece_tokenizer.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uGRHTZ4KPebe"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer\n",
        "\n",
        "# Load the trained tokenizers\n",
        "bpe_tokenizer = Tokenizer.from_file(\"bpe_tokenizer.json\")\n",
        "wordpiece_tokenizer = Tokenizer.from_file(\"wordpiece_tokenizer.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLxCwogFPgKT",
        "outputId": "e3ef2fdf-373b-4b49-b713-9b8113609394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BPE Vocabulary Size: 10000\n",
            "WordPiece Vocabulary Size: 10000\n"
          ]
        }
      ],
      "source": [
        "print(\"BPE Vocabulary Size:\", bpe_tokenizer.get_vocab_size())\n",
        "print(\"WordPiece Vocabulary Size:\", wordpiece_tokenizer.get_vocab_size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkmZNWl5Pi1v",
        "outputId": "7d12beaa-d4d3-407f-8c02-4b8050d68f20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BPE Average Tokens per Sentence: 10.09957276736494\n",
            "WordPiece Average Tokens per Sentence: 12.96194184123484\n"
          ]
        }
      ],
      "source": [
        "def calculate_avg_tokens_per_sentence(tokenizer, file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        code_samples = f.readlines()\n",
        "\n",
        "    total_tokens = 0\n",
        "    total_samples = len(code_samples)\n",
        "\n",
        "    for code in code_samples:\n",
        "        output = tokenizer.encode(code)\n",
        "        total_tokens += len(output.tokens)\n",
        "\n",
        "    return total_tokens / total_samples\n",
        "\n",
        "# Calculate for each tokenizer\n",
        "bpe_avg_tokens = calculate_avg_tokens_per_sentence(bpe_tokenizer, \"held_out_python_code.txt\")\n",
        "wordpiece_avg_tokens = calculate_avg_tokens_per_sentence(wordpiece_tokenizer, \"held_out_python_code.txt\")\n",
        "\n",
        "print(\"BPE Average Tokens per Sentence:\", bpe_avg_tokens)\n",
        "print(\"WordPiece Average Tokens per Sentence:\", wordpiece_avg_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-cE9dZPPkYB",
        "outputId": "b8affa90-ba67-4b30-f02d-788e2b488638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BPE OOV Rate: 0.0\n",
            "WordPiece OOV Rate: 0.00019510514678871283\n"
          ]
        }
      ],
      "source": [
        "def calculate_oov_rate(tokenizer, file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        held_out_code = f.read()\n",
        "\n",
        "    output = tokenizer.encode(held_out_code)\n",
        "    oov_tokens = [token for token in output.tokens if token == \"[UNK]\"]\n",
        "    num_oov_tokens = len(oov_tokens)\n",
        "    total_tokens = len(output.tokens)\n",
        "\n",
        "    return num_oov_tokens / total_tokens\n",
        "\n",
        "# Calculate for each tokenizer\n",
        "bpe_oov_rate = calculate_oov_rate(bpe_tokenizer, \"held_out_python_code.txt\")\n",
        "wordpiece_oov_rate = calculate_oov_rate(wordpiece_tokenizer, \"held_out_python_code.txt\")\n",
        "\n",
        "print(\"BPE OOV Rate:\", bpe_oov_rate)\n",
        "print(\"WordPiece OOV Rate:\", wordpiece_oov_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aCG4dOwUPmAS"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer\n",
        "\n",
        "# Load the trained tokenizer\n",
        "bpe_tokenizer = Tokenizer.from_file(\"bpe_tokenizer.json\")  # or \"wordpiece_tokenizer.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgwS3mFFPnr2",
        "outputId": "14ceecc9-0fda-4698-eb1a-8fa7da0bb33b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: def add(a, b):\n",
            "Tokens: ['def', 'add', '(', 'a', ',', 'b', '):']\n",
            "Token IDs: [4557, 4834, 16, 73, 20, 74, 4538]\n",
            "----------------------------------------\n",
            "Input:     return a + b\n",
            "Tokens: ['return', 'a', '+', 'b']\n",
            "Token IDs: [4594, 73, 19, 74]\n",
            "----------------------------------------\n",
            "Input: def factorial(n):\n",
            "Tokens: ['def', 'factor', 'ial', '(', 'n', '):']\n",
            "Token IDs: [4557, 7227, 5589, 16, 86, 4538]\n",
            "----------------------------------------\n",
            "Input:     if n == 0:\n",
            "Tokens: ['if', 'n', '==', '0', ':']\n",
            "Token IDs: [4536, 86, 4562, 24, 34]\n",
            "----------------------------------------\n",
            "Input:         return 1\n",
            "Tokens: ['return', '1']\n",
            "Token IDs: [4594, 25]\n",
            "----------------------------------------\n",
            "Input:     else:\n",
            "Tokens: ['else', ':']\n",
            "Token IDs: [4742, 34]\n",
            "----------------------------------------\n",
            "Input:         return n * factorial(n - 1)\n",
            "Tokens: ['return', 'n', '*', 'factor', 'ial', '(', 'n', '-', '1', ')']\n",
            "Token IDs: [4594, 86, 18, 7227, 5589, 16, 86, 21, 25, 17]\n",
            "----------------------------------------\n",
            "Input: # This is a comment\n",
            "Tokens: ['#', 'This', 'is', 'a', 'comment']\n",
            "Token IDs: [11, 5329, 4539, 73, 6685]\n",
            "----------------------------------------\n",
            "Input: print('Hello, World!')\n",
            "Tokens: ['print', \"('\", 'Hel', 'lo', ',', 'Wor', 'ld', '!', \"')\"]\n",
            "Token IDs: [4664, 4588, 7722, 4535, 20, 7158, 7117, 9, 4596]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Sample Python code snippets\n",
        "code_samples = [\n",
        "    \"def add(a, b):\",\n",
        "    \"    return a + b\",\n",
        "    \"def factorial(n):\",\n",
        "    \"    if n == 0:\",\n",
        "    \"        return 1\",\n",
        "    \"    else:\",\n",
        "    \"        return n * factorial(n - 1)\",\n",
        "    \"# This is a comment\",\n",
        "    \"print('Hello, World!')\"\n",
        "]\n",
        "\n",
        "# Tokenize each sample and print the results\n",
        "for code in code_samples:\n",
        "    output = bpe_tokenizer.encode(code)\n",
        "    print(f\"Input: {code}\")\n",
        "    print(f\"Tokens: {output.tokens}\")\n",
        "    print(f\"Token IDs: {output.ids}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5ygNVyuPp1Y",
        "outputId": "0171b7a5-5f60-4a4b-ebb4-e60d9129522b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: def add(a, b):\n",
            "Highlighted Tokens: [def] [[a]dd][(][a][,] [b][):]\n",
            "Tokens: ['def', 'add', '(', 'a', ',', 'b', '):']\n",
            "----------------------------------------\n",
            "Input:     return a + b\n",
            "Highlighted Tokens:     [return] [a] [+] [b]\n",
            "Tokens: ['return', 'a', '+', 'b']\n",
            "----------------------------------------\n",
            "Input: def factorial(n):\n",
            "Highlighted Tokens: [def] [factor][ial][(][n][):]\n",
            "Tokens: ['def', 'factor', 'ial', '(', 'n', '):']\n",
            "----------------------------------------\n",
            "Input:     if n == 0:\n",
            "Highlighted Tokens:     [if] [n] [==] [0][:]\n",
            "Tokens: ['if', 'n', '==', '0', ':']\n",
            "----------------------------------------\n",
            "Input:         return 1\n",
            "Highlighted Tokens:         [return] [1]\n",
            "Tokens: ['return', '1']\n",
            "----------------------------------------\n",
            "Input:     else:\n",
            "Highlighted Tokens:     [else][:]\n",
            "Tokens: ['else', ':']\n",
            "----------------------------------------\n",
            "Input:         return n * factorial(n - 1)\n",
            "Highlighted Tokens:         [retur[[n]]] [[n]] [*] [factor][ial][(][[n]] [-] [1][)]\n",
            "Tokens: ['return', 'n', '*', 'factor', 'ial', '(', 'n', '-', '1', ')']\n",
            "----------------------------------------\n",
            "Input: # This is a comment\n",
            "Highlighted Tokens: [#] [Th[is]] [is] [a] [comment]\n",
            "Tokens: ['#', 'This', 'is', 'a', 'comment']\n",
            "----------------------------------------\n",
            "Input: print('Hello, World!')\n",
            "Highlighted Tokens: [print][('][Hel][lo][,] [Wor][ld][!][')]\n",
            "Tokens: ['print', \"('\", 'Hel', 'lo', ',', 'Wor', 'ld', '!', \"')\"]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def visualize_tokenization(tokenizer, text):\n",
        "    output = tokenizer.encode(text)\n",
        "    tokens = output.tokens\n",
        "    highlighted_text = text\n",
        "    for token in tokens:\n",
        "        highlighted_text = highlighted_text.replace(token, f\"[{token}]\")\n",
        "    print(f\"Input: {text}\")\n",
        "    print(f\"Highlighted Tokens: {highlighted_text}\")\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Visualize tokenization for each sample\n",
        "for code in code_samples:\n",
        "    visualize_tokenization(bpe_tokenizer, code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "NOaiA5dlPrhQ"
      },
      "outputs": [],
      "source": [
        "with open(\"tokenized_output.txt\", \"w\") as f:\n",
        "    for code in code_samples:\n",
        "        output = bpe_tokenizer.encode(code)\n",
        "        f.write(f\"Input: {code}\\n\")\n",
        "        f.write(f\"Tokens: {output.tokens}\\n\")\n",
        "        f.write(f\"Token IDs: {output.ids}\\n\")\n",
        "        f.write(\"-\" * 40 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmLOTiZsPuTZ",
        "outputId": "09450c21-f948-4ffa-9475-5766106e1f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenization Time: 25.24 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def measure_tokenization_speed(tokenizer, file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        code_samples = f.readlines()\n",
        "\n",
        "    start_time = time.time()\n",
        "    for code in code_samples:\n",
        "        tokenizer.encode(code)\n",
        "    end_time = time.time()\n",
        "\n",
        "    total_time = end_time - start_time\n",
        "    print(f\"Tokenization Time: {total_time:.2f} seconds\")\n",
        "\n",
        "# Measure speed for BPE tokenizer\n",
        "measure_tokenization_speed(bpe_tokenizer, \"python_code.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqDjCemWPv5I",
        "outputId": "53b68ed3-0628-4acc-b7c9-21be81a38ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Tokens per Sentence: 10.97\n"
          ]
        }
      ],
      "source": [
        "def calculate_avg_tokens_per_sentence(tokenizer, file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        code_samples = f.readlines()\n",
        "\n",
        "    total_tokens = 0\n",
        "    total_samples = len(code_samples)\n",
        "\n",
        "    for code in code_samples:\n",
        "        output = tokenizer.encode(code)\n",
        "        total_tokens += len(output.tokens)\n",
        "\n",
        "    avg_tokens_per_sentence = total_tokens / total_samples\n",
        "    print(f\"Average Tokens per Sentence: {avg_tokens_per_sentence:.2f}\")\n",
        "\n",
        "# Calculate for BPE tokenizer\n",
        "calculate_avg_tokens_per_sentence(bpe_tokenizer, \"python_code.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTqDWGy1PxeL",
        "outputId": "acad5a50-4154-482d-d149-e62594fc5c9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Peak Memory Usage: 524.50 KB\n"
          ]
        }
      ],
      "source": [
        "import tracemalloc\n",
        "\n",
        "def measure_memory_usage(tokenizer, file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        code_samples = f.readlines()\n",
        "\n",
        "    tracemalloc.start()\n",
        "    for code in code_samples:\n",
        "        tokenizer.encode(code)\n",
        "    current, peak = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "\n",
        "    print(f\"Peak Memory Usage: {peak / 1024:.2f} KB\")\n",
        "\n",
        "# Measure memory usage for BPE tokenizer\n",
        "measure_memory_usage(bpe_tokenizer, \"python_code.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qCHb7H-PzA5",
        "outputId": "90d4b9a6-b0a5-4c2b-a692-2c858c458f9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OOV Rate: 0.00%\n"
          ]
        }
      ],
      "source": [
        "def calculate_oov_rate(tokenizer, file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        held_out_code = f.read()\n",
        "\n",
        "    output = tokenizer.encode(held_out_code)\n",
        "    oov_tokens = [token for token in output.tokens if token == \"[UNK]\"]\n",
        "    num_oov_tokens = len(oov_tokens)\n",
        "    total_tokens = len(output.tokens)\n",
        "\n",
        "    oov_rate = num_oov_tokens / total_tokens\n",
        "    print(f\"OOV Rate: {oov_rate * 100:.2f}%\")\n",
        "\n",
        "# Calculate OOV rate for BPE tokenizer\n",
        "calculate_oov_rate(bpe_tokenizer, \"held_out_python_code.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BaV-vvjP0mU",
        "outputId": "c94f7061-3e95-4437-ab1a-2bb3f0ac5fca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compression Ratio: 3.44\n"
          ]
        }
      ],
      "source": [
        "def calculate_compression_ratio(tokenizer, file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        code_samples = f.readlines()\n",
        "\n",
        "    total_chars = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    for code in code_samples:\n",
        "        output = tokenizer.encode(code)\n",
        "        total_chars += len(code)\n",
        "        total_tokens += len(output.tokens)\n",
        "\n",
        "    compression_ratio = total_chars / total_tokens\n",
        "    print(f\"Compression Ratio: {compression_ratio:.2f}\")\n",
        "\n",
        "# Calculate compression ratio for BPE tokenizer\n",
        "calculate_compression_ratio(bpe_tokenizer, \"python_code.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl4WlT4AP2M5",
        "outputId": "faf68959-60b1-4992-902e-ab0156b4861f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Processing Time: 27.60 seconds\n"
          ]
        }
      ],
      "source": [
        "def measure_batch_processing_speed(tokenizer, file_path, batch_size=32):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        code_samples = f.readlines()\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in range(0, len(code_samples), batch_size):\n",
        "        batch = code_samples[i:i + batch_size]\n",
        "        tokenizer.encode_batch(batch)\n",
        "    end_time = time.time()\n",
        "\n",
        "    total_time = end_time - start_time\n",
        "    print(f\"Batch Processing Time: {total_time:.2f} seconds\")\n",
        "\n",
        "# Measure batch processing speed for BPE tokenizer\n",
        "measure_batch_processing_speed(bpe_tokenizer, \"python_code.txt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08a49e224f3043358f77fc0c6c5bbd29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e53b6b865b8e41fbbf12592321856fa8",
            "max": 917,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cda142d7c5df429a9f3c3e6c5cd8c0b6",
            "value": 917
          }
        },
        "2e0f47d5f132402faa9f9733a889055b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35cf516beb3f4e15b7d908ddd9f148a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "364bc5c2cbf64d439bcf02cab4f3502f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "439f09348e1b4d058a4e70e26cdcdc04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e256c9f504546e3afc2f311c3be9263",
            "placeholder": "​",
            "style": "IPY_MODEL_d59cf93c137844928e43120b543179bb",
            "value": " 917/917 [00:00&lt;00:00, 57.94it/s]"
          }
        },
        "6a1608dd1fb948af96ea4de4ba06d2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e05646c1b204ee68c8d9af022ac7931": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e0a431fb92343f7b0ecb10923998437": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2a7ae97e6d54672a47b182873d24ca5",
            "placeholder": "​",
            "style": "IPY_MODEL_bac57e80a4074946ac510eadb81187ff",
            "value": "Resolving data files: 100%"
          }
        },
        "9e256c9f504546e3afc2f311c3be9263": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f8c1ccb7af54a048d32b84908ef75b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35cf516beb3f4e15b7d908ddd9f148a8",
            "placeholder": "​",
            "style": "IPY_MODEL_c618d8b7a73647aab016fc96c81c1959",
            "value": "Resolving data files: 100%"
          }
        },
        "a58682dd26a9455e97339011524841a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f8c1ccb7af54a048d32b84908ef75b6",
              "IPY_MODEL_ce44d90249c24c1599e16fab4e7b8ea2",
              "IPY_MODEL_f6b9a83d310a4d008786d8502872736f"
            ],
            "layout": "IPY_MODEL_e3595975c9e64becbf2958dc32871212"
          }
        },
        "b2a7ae97e6d54672a47b182873d24ca5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bac57e80a4074946ac510eadb81187ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c618d8b7a73647aab016fc96c81c1959": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cda142d7c5df429a9f3c3e6c5cd8c0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce44d90249c24c1599e16fab4e7b8ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e0f47d5f132402faa9f9733a889055b",
            "max": 917,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a1608dd1fb948af96ea4de4ba06d2e9",
            "value": 917
          }
        },
        "d59cf93c137844928e43120b543179bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3595975c9e64becbf2958dc32871212": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e53b6b865b8e41fbbf12592321856fa8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd3caac3823445bae4b7dfb1e25bb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e0a431fb92343f7b0ecb10923998437",
              "IPY_MODEL_08a49e224f3043358f77fc0c6c5bbd29",
              "IPY_MODEL_439f09348e1b4d058a4e70e26cdcdc04"
            ],
            "layout": "IPY_MODEL_7e05646c1b204ee68c8d9af022ac7931"
          }
        },
        "f6b9a83d310a4d008786d8502872736f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_364bc5c2cbf64d439bcf02cab4f3502f",
            "placeholder": "​",
            "style": "IPY_MODEL_fa6015372b6546cb9b0de03fecc9a963",
            "value": " 917/917 [00:00&lt;00:00, 583.80it/s]"
          }
        },
        "fa6015372b6546cb9b0de03fecc9a963": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
